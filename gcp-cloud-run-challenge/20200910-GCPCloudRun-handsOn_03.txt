3) Create Managed Instance Groups

애플리케이션의 확장을 허용하기 위해 관리 형 인스턴스 그룹이 생성되고 frontend 및 backend 인스턴스를 인스턴스 템플릿으로 사용합니다.

관리 형 인스턴스 그룹 (MIG)에는 단일 영역에서 단일 항목으로 관리 할 수있는 동일한 인스턴스가 포함됩니다. 관리 형 인스턴스 그룹은 인스턴스를 사전에 사용 가능한 상태, 즉 RUNNING 상태로 유지하여 앱의 고 가용성을 유지합니다. 프런트 엔드 및 백엔드 인스턴스에 관리 형 인스턴스 그룹을 사용하여 자동 복구, 부하 분산, 자동 확장, 롤링 업데이트를 제공합니다.

자동 복구, 
부하 분산, 
자동 확장, 
롤링 업데이트


1. Create Instance Template from Source Instance

*관리 형 인스턴스 그룹을 만들려면 먼저 그룹의 기반이 될 인스턴스 템플릿을 만들어야합니다. 인스턴스 템플릿을 사용하면 새 VM 인스턴스를 만들 때 사용할 머신 유형, 부팅 디스크 이미지 또는 컨테이너 이미지, 네트워크, 기타 인스턴스 속성을 정의 할 수 있습니다. 인스턴스 템플릿을 사용하여 관리 형 인스턴스 그룹에 인스턴스를 만들거나 개별 인스턴스를 만들 수도 있습니다.


gcloud compute instances stop frontend
gcloud compute instances stop backend

gcloud compute instance-templates create fancy-fe \
    --source-instance=frontend \
    --source-instance-zone=asia-northeast3-a

gcloud compute instance-templates create fancy-be \
    --source-instance=backend \
    --source-instance-zone=asia-northeast3-a

gcloud compute instance-templates list




2. Create managed instance group

gcloud compute instance-groups managed create fancy-fe-mig \
    --base-instance-name fancy-fe \
    --size 2 \
    --template fancy-fe


gcloud compute instance-groups managed create fancy-be-mig \
    --base-instance-name fancy-be \
    --size 2 \
    --template fancy-be

gcloud compute instance-groups managed list



*For your application, the frontend microservice runs on port 8080, and the backend microservice runs on port 8081 for orders and port 8082 for products:

gcloud compute instance-groups set-named-ports fancy-fe-mig \
    --named-ports frontend:8080

gcloud compute instance-groups set-named-ports fancy-be-mig \
    --named-ports orders:8081,products:8082

*이들은 비표준 포트이므로 이를 식별하기 위해 명명된 포트(named port)를 지정합니다. 명명된 포트는 서비스 이름과 서비스가 실행되는 포트를 나타내는 키 : 값 쌍 메타 데이터입니다. 이름이 지정된 포트를 인스턴스 그룹에 할당 할 수 있으며 이는 그룹의 모든 인스턴스에서 서비스를 사용할 수 있음을 나타냅니다. 이 정보는 나중에 구성 될 HTTP 부하 분산 서비스(Load Balancing service)에서 사용됩니다.



3. Configure autohealing


*애플리케이션 자체의 가용성을 개선하고 응답하는지 확인하려면 관리 형 인스턴스 그룹에 대한 자동 복구 정책을 구성하세요.

*자동 복구 정책은 애플리케이션 기반 상태 확인을 사용하여 앱이 예상대로 응답하는지 확인합니다. 앱이 응답하는지 확인하는 것은 인스턴스가 기본 동작 인 RUNNING 상태에 있는지 확인하는 것보다 더 정확합니다.

*Create a health check that repairs the instance if it returns "unhealthy" 3 consecutive times for the frontend and backend:

gcloud compute health-checks create http fancy-fe-hc \
    --port 8080 \
    --check-interval 30s \
    --healthy-threshold 1 \
    --timeout 10s \
    --unhealthy-threshold 3


gcloud compute health-checks create http fancy-be-hc \
    --port 8081 \
    --request-path=/api/orders \
    --check-interval 30s \
    --healthy-threshold 1 \
    --timeout 10s \
    --unhealthy-threshold 3


*Create a firewall rule to allow the health check probes to connect to the microservices on ports 8080-8081:
gcloud compute firewall-rules create allow-health-check \
    --allow tcp:8080-8081 \
    --source-ranges 130.211.0.0/22,35.191.0.0/16 \
    --network custom-network1

*Apply the health checks to their respective services:
gcloud compute instance-groups managed update fancy-fe-mig \
    --health-check fancy-fe-hc \
    --initial-delay 300

gcloud compute instance-groups managed update fancy-be-mig \
    --health-check fancy-be-hc \
    --initial-delay 300



4. Create Load Balancers
*관리 형 인스턴스 그룹을 완성하기 위해 HTTP (S) 부하 분산기를 사용하여 프런트 엔드 및 백엔드 마이크로 서비스에 트래픽을 제공하고 매핑을 사용하여 경로 지정 규칙에 따라 적절한 백엔드 서비스로 트래픽을 보냅니다. 이렇게하면 모든 서비스에 대해 단일 부하 분산 된 IP가 노출됩니다.
https://cloud.google.com/load-balancing/docs/load-balancing-overview


*Create HTTP(S) Load Balancer
Google Cloud Platform은 다양한 유형의 부하 분산기를 제공합니다. 이 실습에서는 트래픽에 HTTP (S) 부하 분산기를 사용합니다. HTTP 부하 분산기는 다음과 같이 구성됩니다.

전달 규칙은 수신 요청을 대상 HTTP 프록시로 보냅니다.
대상 HTTP 프록시는 URL 맵에 대해 각 요청을 확인하여 요청에 적합한 백엔드 서비스를 결정합니다.
백엔드 서비스는 연결된 백엔드의 제공 용량, 영역, 인스턴스 상태에 따라 각 요청을 적절한 백엔드로 보냅니다. 각 백엔드 인스턴스의 상태는 HTTP 상태 확인을 사용하여 확인됩니다. 백엔드 서비스가 HTTPS 또는 HTTP / 2 상태 확인을 사용하도록 구성된 경우 요청은 백엔드 인스턴스로가는 도중에 암호화됩니다.
부하 분산기와 인스턴스 간의 세션은 HTTP, HTTPS 또는 HTTP / 2 프로토콜을 사용할 수 있습니다. HTTPS 또는 HTTP / 2를 사용하는 경우 백엔드 서비스의 각 인스턴스에는 SSL 인증서가 있어야합니다.


For demonstration purposes in order to avoid SSL certificate complexity, use HTTP instead of HTTPS. For production, it is recommended to use HTTPS for encryption wherever possible.

*Create health checks that will be used to determine which instances are capable of serving traffic for each service:

gcloud compute http-health-checks create fancy-fe-frontend-hc \
  --request-path / \
  --port 8080

gcloud compute http-health-checks create fancy-be-orders-hc \
  --request-path /api/orders \
  --port 8081

gcloud compute http-health-checks create fancy-be-products-hc \
  --request-path /api/products \
  --port 8082

gcloud compute http-health-checks list

*These health checks are for the load balancer, and only handle directing traffic from the load balancer; they do not cause the managed instance groups to recreate instances.


*Create backend services that are the target for load-balanced traffic. The backend services will use the health checks and named ports you created:


gcloud compute backend-services create fancy-fe-frontend \
  --http-health-checks fancy-fe-frontend-hc \
  --port-name frontend \
  --network custom-network1 \
  --global

gcloud compute backend-services create fancy-be-orders \
  --http-health-checks fancy-be-orders-hc \
  --port-name orders \
  --network custom-network1 \
  --global

gcloud compute backend-services create fancy-be-products \
  --http-health-checks fancy-be-products-hc \
  --port-name products \
  --network custom-network1 \
  --global

gcloud compute backend-services listCloud Armor security policies create logs that can be explored to determine when traffic is denied and when it is allowed, along with the source of the traffic.

*Add the Load Balancer's backend services:


gcloud compute backend-services add-backend fancy-fe-frontend \
  --instance-group fancy-fe-mig \
  --instance-group-zone asia-northeast3-a \
  --global

gcloud compute backend-services add-backend fancy-be-orders \
  --instance-group fancy-be-mig \
  --instance-group-zone asia-northeast3-a \
  --global


gcloud compute backend-services add-backend fancy-be-products \
  --instance-group fancy-be-mig \
  --instance-group-zone asia-northeast3-a \
  --global

gcloud compute backend-services list

*Create a URL map. The URL map defines which URLs are directed to which backend services:

gcloud compute url-maps create fancy-map \
  --default-service fancy-fe-frontend

*Create a path matcher to allow the /api/orders and /api/products paths to route to their respective services:
gcloud compute url-maps add-path-matcher fancy-map \
   --default-service fancy-fe-frontend \
   --path-matcher-name fancy-map-matcher \
   --path-rules "/api/orders=fancy-be-orders,/api/products=fancy-be-products"
*혹시 path-matcher를 잘못 생성했으면 gcloud compute url-maps remove-path-matcher fancy-map --path-matcher-name fancy-map-matcher 명령으로 삭제 가능합니다.

gcloud compute url-maps 


*Create the proxy which ties to the URL map:

gcloud compute target-http-proxies create fancy-proxy \
  --url-map fancy-map

gcloud compute target-http-proxies list

gcloud compute forwarding-rules create fancy-http-rule \
  --global \
  --target-http-proxy fancy-proxy \
  --ports 80

gcloud compute forwarding-rules list


5. Update Configuration

cd ~/monolith-to-microservices/react-app/
gcloud compute forwarding-rules list --global


*Return to the Cloud Shell Editor and edit the .env file again to point to Public IP of Load Balancer. [LB_IP] represents the External IP address of the backend instance determined above.
--
REACT_APP_ORDERS_URL=http://[LB_IP]/api/orders
REACT_APP_PRODUCTS_URL=http://[LB_IP]/api/products
---
*The ports are removed in the new address because the load balancer is configured to handle this forwarding for you.


*Rebuild react-app, which will update the frontend code:
cd ~/monolith-to-microservices/react-app
npm install && npm run-script build

*Copy the application code into your bucket:
cd ~
rm -rf monolith-to-microservices/*/node_modules
gsutil -m cp -r monolith-to-microservices gs://fancy-store-$DEVSHELL_PROJECT_ID/




6. Update the frontend instances
*
gcloud compute instance-groups managed rolling-action replace fancy-fe-mig \
    --max-unavailable 100%
*In this example of a rolling replace, you specifically state that all machines can be replaced immediately through the --max-unavailable parameter. Without this parameter, the command would keep an instance alive while restarting others to ensure availability. For testing purposes, you specify to replace all immediately for speed.




7. Test the website
*rolling-action replace 명령어를 실행 한 후 약 30 초 동안 기다렸다가 인스턴스를 처리 할 시간을 준 다음 인스턴스가 목록에 나타날 때까지 관리 형 인스턴스 그룹의 상태를 확인합니다.
watch -n 2 gcloud compute instance-groups list-instances fancy-fe-mig
*Once items appear in the list, exit the watch command by pressing Ctrl+C.

*Run the following to confirm the service is listed as HEALTHY:
watch -n 2 gcloud compute backend-services get-health fancy-fe-frontend --global
*Wait until the 2 services are listed as HEALTHY.
*Once both items appear as HEALTHY on the list, exit the watch command by pressing Ctrl+C.


*The application will be accessible via http://[LB_IP] where [LB_IP] is the IP_ADDRESS specified for the Load Balancer, which can be found with the following command:

gcloud compute forwarding-rules list --global

*You'll be checking the application later in the lab.




8. Scaling GCE
*지금까지 각각 2 개의 인스턴스가 있는 2 개의 관리 형 인스턴스 그룹을 만들었습니다. 이 구성은 잘 작동하지만 부하에 관계 없는 정적 구성입니다. 다음으로 사용률에 따라 자동 확장 정책을 만들어 각 관리 형 인스턴스 그룹을 자동으로 확장합니다.

9. Automatically Resize by Utilization
*To create the autoscaling policy, execute the following (--max-num-replicas는 최대로 띄울 인스턴스의 개수를 입력합니다. 여기서는 Qwiklabs 시스템의 제약으로 2로 지정합니다):

gcloud compute instance-groups managed set-autoscaling \
  fancy-fe-mig \
  --max-num-replicas 2 \
  --target-load-balancing-utilization 0.60


gcloud compute instance-groups managed set-autoscaling \
  fancy-be-mig \
  --max-num-replicas 2 \
  --target-load-balancing-utilization 0.60


gcloud compute instance-groups managed list




(결과입력) 
gcloud compute forwarding-rules list --global && gcloud compute instance-groups managed describe --zone asia-northeast3-a fancy-fe-mig | head -n 15



